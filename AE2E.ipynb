{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreshMag/omr-img2midi/blob/master/AE2E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmented End-to-End - Setup\n",
        "In this notebook we will use in practice all the code written for the Augmented End-to-End part of the project."
      ],
      "metadata": {
        "id": "fbp_4Cr8aJjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the required code and models\n",
        "\n",
        "We need first to clone the repository with the code we need plus the original model built and trained by Carlo-Zaragoza on the PrImuS dataset"
      ],
      "metadata": {
        "id": "EDzwJzMtvo36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FreshMag/omr-img2midi.git\n",
        "%cd omr-img2midi\n",
        "!mkdir models\n",
        "%cd models\n",
        "!wget https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip\n",
        "!unzip Semantic-Model.zip -d semantic\n",
        "!rm Semantic-Model.zip\n",
        "%cd ../..\n",
        "!mkdir outputs\n",
        "%cd omr-img2midi"
      ],
      "metadata": {
        "id": "qg8-igFX2xxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the Java tools for conversion: `semantic → MIDI/MEI`\n",
        "\n",
        "This is necessary to view our produced symbols in other more readable formats. This tool was developed by Carlo-Zaragoza and converts a file written in semantic format to MEI or MIDI format."
      ],
      "metadata": {
        "id": "B5jbyDjJ8wEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://grfia.dlsi.ua.es/primus/primus_converter.tgz\n",
        "!tar xzvf primus_converter.tgz\n",
        "!mv primus_conversor/omr-3.0-SNAPSHOT.jar ./converter/omr-3.0-SNAPSHOT.jar\n",
        "!rm -rf ./primus_conversor\n",
        "!rm ./primus_converter.tgz"
      ],
      "metadata": {
        "id": "TMlGNe_s8R7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing required libraries\n",
        "\n",
        "All the libraries specified by ``pyproject.toml`` are installed + the library ``verovio`` used for rendering MEI files into SVG."
      ],
      "metadata": {
        "collapsed": false,
        "id": "xLmKgc6QtuxM"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "!pip install \"/content/omr-img2midi\"\n",
        "!pip install verovio\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/omr-img2midi/src')"
      ],
      "metadata": {
        "id": "sFlscMJWtuxM"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import of python libraries and setup\n",
        "\n",
        "Some of the used libraries are imported and the main paths are defined."
      ],
      "metadata": {
        "id": "9q7fbmTO9QT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from semantic.sheet import EncodedSheet\n",
        "from semantic.end2end.ctc_predict import CTC\n",
        "import verovio\n",
        "import cv2\n",
        "\n",
        "base_path = \"/content/omr-img2midi/\"\n",
        "model_path = base_path + \"models/semantic/semantic_model.meta\"\n",
        "input_image_path = \"/content/\"\n",
        "vocabulary_path = base_path + \"data/vocabulary_semantic.txt\"\n",
        "\n",
        "outputs_path = \"/content/outputs/\"\n"
      ],
      "metadata": {
        "id": "aun5l_YjA7ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions\n",
        "\n",
        "The following functions are used in the rest of the code. They are trivial."
      ],
      "metadata": {
        "id": "GHTQ8-wY7mgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG, display, Markdown\n",
        "import os\n",
        "\n",
        "def get_filename_with_ex(filename, extension):\n",
        "  return filename[:filename.rfind(\".\")] + \".\" + extension\n",
        "\n",
        "def show_svg_file(filename):\n",
        "  display(SVG(filename=filename))\n",
        "\n",
        "def show_markdown(markdown_str):\n",
        "  display(Markdown(markdown_str))\n",
        "\n",
        "def mei2svg(input_mei_file, output_svg_file):\n",
        "  tk = verovio.toolkit()\n",
        "  tk.loadFile(input_mei_file)\n",
        "\n",
        "  # Setting of verovio layout options\n",
        "  options = {\n",
        "      \"scale\": 40,\n",
        "      \"adjustPageHeight\": True,\n",
        "      \"backgroundColor\": \"white\"  # White background color\n",
        "  }\n",
        "\n",
        "  tk.setOptions(options)\n",
        "  tk.renderToSVGFile(output_svg_file, 1)\n"
      ],
      "metadata": {
        "id": "baukbUch7mNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting test image\n",
        "\n",
        "We need now to get a test image to apply our algorithm"
      ],
      "metadata": {
        "id": "aAlb1BODyqao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!gdown 19hz4krss-w-q3PEiMu8KeB2PUiB0HXE9"
      ],
      "metadata": {
        "id": "y8Kirz6HyqGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input displayed"
      ],
      "metadata": {
        "id": "MDQ3cwA9m4Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Set the image name here\n",
        "image_name = \"test_end2end.jpg\"\n",
        "\n",
        "final_input_path = input_image_path + image_name\n",
        "photo = cv2.imread(final_input_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "cv2_imshow(cv2.resize(photo, (photo.shape[1] // 4, photo.shape[0] // 4)))"
      ],
      "metadata": {
        "id": "K-ciViI13uIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Application of the algorithms\n",
        "\n",
        "In the following cells we now apply all the algorithms implemented in this project."
      ],
      "metadata": {
        "id": "c2HTnlfRnun-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First part - Scanning\n",
        "\n",
        "Here we scan the photo, using the `img2doc.scan` function. The produced image is a scanned-like image."
      ],
      "metadata": {
        "id": "20PMIVLRnArV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import core.img2doc.scanner as img2doc\n",
        "scanned = img2doc.scan(photo)\n",
        "\n",
        "cv2_imshow(cv2.resize(scanned, (scanned.shape[1] // 4, scanned.shape[0] // 4)))"
      ],
      "metadata": {
        "id": "0IPWac0M2jrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second part - Segmentation\n",
        "\n",
        "Here we divide the scanned image in segments using the ``doc2segments.segment_doc`` function. The result is a list of sub-images, each part of the input of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qr0OmQvz28e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from core.doc2segments.segmentation import doc2segments\n",
        "\n",
        "segments = doc2segments.segment_doc(scanned)\n",
        "\n",
        "cv2_imshow(segments[0])"
      ],
      "metadata": {
        "id": "gj6y2q4w280L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage of the model\n",
        "\n",
        "We can now feed our produced segments into the model. For this, a utility function is been used: ``end2end_recognition``. This function takes a list of segments, the object encapsulating the model and the path to the vocabulary used by the model."
      ],
      "metadata": {
        "id": "kkPqDt7L4Jkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from semantic.end2end.ctc_predict import CTC\n",
        "from util import end2end_recognition\n",
        "\n",
        "model = CTC(model_file_path=model_path)\n",
        "sheet, subsheets = end2end_recognition(segments, model=model, vocabulary_path=vocabulary_path)"
      ],
      "metadata": {
        "id": "vC9ZHqzh4LRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output\n",
        "\n",
        "The result of the recognition is an instance of the class ``EncodedSheet``. This class contains several utility methods that we can use to get the result in multiple formats."
      ],
      "metadata": {
        "id": "VxX2HyLuXczu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Symbols printed\n",
        "Here we print a list of the symbols produced by the model."
      ],
      "metadata": {
        "id": "EvG0aVyXpVJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sheet.print_symbols()"
      ],
      "metadata": {
        "id": "dK1IMR374feB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output to file\n",
        "\n",
        "Using the method inside ``EncodedSheet``, we output the result of the prediction inside a file with  ``.semantic`` extension."
      ],
      "metadata": {
        "id": "58Zh9PdwZbMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_filename = get_filename_with_ex(image_name, \"semantic\")\n",
        "semantic_path = outputs_path + semantic_filename\n",
        "\n",
        "sheet.clean(symbol=\"tie\")\n",
        "sheet.write_to_file(semantic_path, separator=\"\\t\")"
      ],
      "metadata": {
        "id": "LxwOLgUwZaNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Showing the results\n",
        "\n",
        "We can now convert the symbols we found onto different formats, for example the MEI format."
      ],
      "metadata": {
        "id": "WI2-sxtlpmOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation of the MEI file\n",
        "\n",
        "Using the tool we previously downloaded, we can convert the file with the `.semantic` extension into a file with `.mei` extension.\n"
      ],
      "metadata": {
        "id": "WwD5pKoB308t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mei_filename = get_filename_with_ex(image_name, \"mei\")\n",
        "output_mei_path = outputs_path + mei_filename\n",
        "\n",
        "print(f\"Converting to {output_mei_path}\")\n",
        "%cd /content/omr-img2midi\n",
        "!./converter.sh {semantic_path} {output_mei_path}"
      ],
      "metadata": {
        "id": "JMiwr4YD3-_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rendering MEI file into SVG\n",
        "\n",
        "Using the `verovio` library, we now convert the `.mei` file into a `.svg` file."
      ],
      "metadata": {
        "id": "zkt8iDxZY_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_svg_path = outputs_path + get_filename_with_ex(image_name, \"svg\")\n",
        "\n",
        "# utility function that converts MEI file into SVG file\n",
        "mei2svg(output_mei_path, output_svg_path)\n"
      ],
      "metadata": {
        "id": "O6VEVSpL5A_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show the result\n",
        "\n",
        "Here we show the produced SVG file."
      ],
      "metadata": {
        "id": "yoeacrf3MgIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "show_markdown(\"## Generated Input\")\n",
        "show_svg_file(output_svg_path)"
      ],
      "metadata": {
        "id": "-n7WaUxqMf-m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}