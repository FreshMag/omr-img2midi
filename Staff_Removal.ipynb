{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOGByLAbaHPdjlDQvhL7MK2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download the trained model *StaffUNet2* and test image\n",
        "\n",
        "Here we download the required files hosted on Google Drive using `gdown` command."
      ],
      "metadata": {
        "id": "Uzd9DDWDJTxK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHFgwAHa0TlD"
      },
      "outputs": [],
      "source": [
        "# Get model\n",
        "!gdown 1KfsaSoGQOjtUo_A2_J-GZ8F8rAxWvbpX\n",
        "# Get test image\n",
        "!gdown 1hF36KTun8wHNAi8DMzgexGm8SgyWilI6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "Q5AQ1p6ZKC3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "import cv2"
      ],
      "metadata": {
        "id": "3gRPE_Oi0d66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility functions\n",
        "\n",
        "For this model, `jaccard_index` function was used for computing metrics during the training. When loading the model we require to input also the requirements, so this function is defined here as well.\n",
        "\n",
        "`get_model` is a utility function to load the model given its path."
      ],
      "metadata": {
        "id": "Cd5ugs6VKG6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smooth = 1e-12\n",
        "\n",
        "def jaccard_index(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "\n",
        "    return K.mean(jac)\n",
        "\n",
        "def get_model(model_path):\n",
        "    dependencies = {'jaccard_index': jaccard_index}\n",
        "    model = keras.models.load_model(model_path, custom_objects=dependencies)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KzHeWuCO0lEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show image\n",
        "\n",
        "Simple function for showing images using `matplotlib` library."
      ],
      "metadata": {
        "id": "f6f_Q1a1KrdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image):\n",
        "  _, axs = plt.subplots()\n",
        "  axs.imshow(image, cmap='gray')\n",
        "  axs.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9RMO4AS8-902"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core\n",
        "\n",
        "Our model is trained on 512x512 images so, in order to use it on variable sized sheet music images, we need another method.\n",
        "\n",
        "## Chunks\n",
        "\n",
        "This approach is based on dividing the image in **chunks**: pieces of the image of size 512x512. If the size of the image is not multiple of this chunk size, we make a white border of right and bottom side of the image.\n",
        "The two functions defined here do the following:\n",
        "\n",
        "\n",
        "*   `divide_in_chunks` takes an image and returns a list of chunks of size `chunk_size` plus some smaller edge chunks that are smaller (if width and height aren't multiple of `chunk_size`\n",
        "*   `reassemble_image` takes a list of chunks and return the reassembled image\n",
        "\n"
      ],
      "metadata": {
        "id": "INmfsZe5K3iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_in_chunks(image, chunk_size=512):\n",
        "    img_chunks = []\n",
        "    for x in range(0, image.shape[1], chunk_size):\n",
        "        for y in range(0, image.shape[0], chunk_size):\n",
        "            y2 = min(y + chunk_size, image.shape[0])\n",
        "            x2 = min(x + chunk_size, image.shape[1])\n",
        "            img_chunk = image[y:y2, x:x2]\n",
        "            img_chunks.append(img_chunk)\n",
        "\n",
        "    return img_chunks\n",
        "\n",
        "def reassemble_image(chunks, width, height, chunk_size):\n",
        "    rows = (height // chunk_size)\n",
        "    if height % chunk_size != 0:\n",
        "       rows += 1\n",
        "\n",
        "    assembled_image = np.empty((height, 0, 3), dtype=np.uint8)\n",
        "    i = 0\n",
        "    while i < len(chunks):\n",
        "        column = chunks[i]\n",
        "        j = i + 1\n",
        "        while j % rows != 0:\n",
        "            column = np.concatenate((column, chunks[j]), axis=0)\n",
        "            j += 1\n",
        "        assembled_image = np.hstack((assembled_image, column))\n",
        "        i += rows\n",
        "\n",
        "    return assembled_image"
      ],
      "metadata": {
        "id": "JuesTkAh1AN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk normalization\n",
        "\n",
        "Each chunk is a piece of image, but this could still not be in the right format. For example, for how the model was trained, the symbols of the image must **white on black background**, so we need to perform a `bitwise_not`.\n",
        "\n",
        "During the test of the model, it has been tried to add borders to chunks as *safety borders*, to see if the produced image was better \"understood\" by the model. The option has been kept available.\n",
        "\n",
        "This function has been developed to work also with chunks of sizes different from `chunk_size`. If we adjust image size as previously described, however, there is no need to check for chunk sizes. This option was made available during previous version of this notebook, and it still is. So, if we submit a chunk of different sizes, this function adds borders to the dimensions to make the image square and then of the correct size."
      ],
      "metadata": {
        "id": "5atxuoyd1h93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(image, safety_border=0, chunk_size=512):\n",
        "    img = image.copy()\n",
        "\n",
        "    if len(image.shape) > 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    border_v, border_h = (0, 0)\n",
        "    if img.shape[0] < chunk_size <= img.shape[1]:\n",
        "        img = img[:, :chunk_size]\n",
        "        border_v = int((chunk_size - img.shape[0]) / 2) + 1\n",
        "    elif img.shape[1] < chunk_size <= img.shape[0]:\n",
        "        img = img[:chunk_size, :]\n",
        "        border_h = int((chunk_size - img.shape[1]) / 2) + 1\n",
        "    elif img.shape[0] < chunk_size and img.shape[1] < chunk_size:\n",
        "        border_v = int((chunk_size - img.shape[0]) / 2) + 1\n",
        "        border_h = int((chunk_size - img.shape[1]) / 2) + 1\n",
        "\n",
        "    if border_v != 0 or border_h != 0:\n",
        "      img = cv2.copyMakeBorder(img, border_v, border_v, border_h, border_h, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "      img = img[:chunk_size, :chunk_size]\n",
        "    if safety_border != 0:\n",
        "      img = cv2.copyMakeBorder(img, safety_border, safety_border, safety_border, safety_border,\n",
        "                             cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
        "      img = cv2.resize(img, (chunk_size, chunk_size))\n",
        "\n",
        "    img = cv2.bitwise_not(img)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    return img, border_h, border_v\n"
      ],
      "metadata": {
        "id": "q2VzSL661Am9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Staff Remover\n",
        "\n",
        "The following class represents the main tool to perform Staff line removal. The only method meant to be used from outside is `remove_staffs`, the others are used internally. The only required parameter is `images`, that is a list of chunks.\n",
        "\n",
        "It first performs the previously described normalization, and then uses the loaded model `StaffUNet2`. After that, the obtained mask is fist dilated vertically to better cover the staff lines, and then it's applied on the chunk (the mask is used to delete the related pixel).\n",
        "\n",
        "The processed chunks with staffs removed are returned."
      ],
      "metadata": {
        "id": "bRuzvxiq796T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StaffRemover:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = get_model(model_path)\n",
        "        self.safety_border = 0\n",
        "        self.input_images, borders_h, borders_v, images, pred_bin = None, None, None, None, None\n",
        "\n",
        "    def prepare_chunks(self):\n",
        "        input_images = []\n",
        "        borders_h = []\n",
        "        borders_v = []\n",
        "        for image in self.images:\n",
        "          input_image, border_h, border_v = normalize_image(image, self.safety_border)\n",
        "          input_images.append(input_image)\n",
        "          borders_h.append(border_h)\n",
        "          borders_v.append(border_v)\n",
        "\n",
        "        input_images = np.array(input_images)\n",
        "        input_images = (input_images / 255)\n",
        "        input_images = input_images.astype(np.float32)\n",
        "        return input_images, borders_h, borders_v\n",
        "\n",
        "    def process_result(self, index):\n",
        "      output = np.squeeze(self.pred_bin[index], axis=2)\n",
        "      kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 3))\n",
        "\n",
        "      output_converted = output.astype(np.uint8)\n",
        "      dilated = cv2.morphologyEx(output_converted, cv2.MORPH_DILATE, kernel)\n",
        "      mask = dilated == 1\n",
        "\n",
        "      black_color = np.zeros(shape=(512, 512, 3))\n",
        "\n",
        "      # Apply the mask to retain BGR values where the mask is True\n",
        "      result = ((np.where(mask[..., None], black_color, [self.input_images[index]])[0]) * 255).astype(np.uint8)\n",
        "      _, result = cv2.threshold(result, 50, 255, cv2.THRESH_BINARY)\n",
        "      result = cv2.bitwise_not(result)\n",
        "      # Remove the safety border\n",
        "      result = cv2.resize(result, (512 + self.safety_border*2, 512 + self.safety_border*2))\n",
        "      if self.safety_border != 0:\n",
        "        result = result[self.safety_border:-self.safety_border, self.safety_border:-self.safety_border, :]\n",
        "\n",
        "      def show_chunk_progress(index):\n",
        "          _, axs = plt.subplots(1, 3)\n",
        "          axs[0].imshow(self.images[index], cmap='gray')\n",
        "          axs[0].axis('off')\n",
        "          axs[1].imshow(output_converted, cmap='gray')\n",
        "          axs[1].axis('off')\n",
        "          axs[2].imshow(result, cmap='gray')\n",
        "          axs[2].axis('off')\n",
        "          plt.show()\n",
        "\n",
        "      # show_chunk_progress(i)\n",
        "      return result\n",
        "\n",
        "\n",
        "    def remove_staffs(self, images, thresh=0.6, safety_border=0):\n",
        "      self.images = images\n",
        "      self.safety_border = safety_border\n",
        "      self.input_images, borders_h, borders_v = self.prepare_chunks()\n",
        "\n",
        "      preds = self.model.predict(self.input_images)\n",
        "      optimal_bin_thr = thresh\n",
        "      self.pred_bin = (preds >= optimal_bin_thr).astype(np.int64)\n",
        "\n",
        "      results = []\n",
        "      for i in range(self.pred_bin.shape[0]):\n",
        "        result = self.process_result(i)\n",
        "        h, w, _ = result.shape\n",
        "\n",
        "        results.append(result[max(borders_v[i]-1, 0):min(h-borders_v[i]+1, h), max(borders_h[i]-1, 0):min(w-borders_h[i]+1, w)])\n",
        "\n",
        "      self.images = None\n",
        "      self.safety_border = None\n",
        "      self.input_images = None\n",
        "      self.safety_border = 0\n",
        "      self.pred_bin = None\n",
        "      return results\n"
      ],
      "metadata": {
        "id": "ViCCARXD1Gnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image size adjustment\n",
        "\n",
        "Instead of changing every chunk by adding the correct border, we change the size of the entire image to be multiple of `chunk_size` adding a white border."
      ],
      "metadata": {
        "id": "XomN_i5EEc30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_image_size(image, chunk_size=512):\n",
        "  h, w = image.shape[0], image.shape[1]\n",
        "  borders = [0, 0]\n",
        "  if h % chunk_size != 0:\n",
        "    new_h = chunk_size * ((h // chunk_size ) + 1)\n",
        "    borders[0] = new_h - h\n",
        "  if w % chunk_size != 0:\n",
        "    new_w = chunk_size * ((w // chunk_size ) + 1)\n",
        "    borders[1] = new_w - w\n",
        "\n",
        "  return cv2.copyMakeBorder(image, 0, borders[0], 0, borders[1], cv2.BORDER_CONSTANT, value=[255, 255, 255])"
      ],
      "metadata": {
        "id": "ivqSrZH2M9f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage\n",
        "\n",
        "We are ready to use our staff remover on sheet music images\n",
        "\n",
        "## Loading of the image and chunks\n",
        "We first read the image using the OpenCV library, we adjust its dimensions and then we divide it into chunks using the previous functions."
      ],
      "metadata": {
        "id": "q4g2dedqE-5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"/content/test_staff.png\", cv2.IMREAD_COLOR)\n",
        "h, w = image.shape[0], image.shape[1]\n",
        "adjusted = adjust_image_size(image)\n",
        "new_h, new_w = adjusted.shape[0], adjusted.shape[1]\n",
        "chunks = divide_in_chunks(adjusted)"
      ],
      "metadata": {
        "id": "-_mfgjY61K-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Staff remover usage\n",
        "\n",
        "We use the StaffRemover class, first passing the model path and then calling the `remove_staffs` on the list of chunks."
      ],
      "metadata": {
        "id": "UxXo2AoxFeKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remover = StaffRemover(\"/content/StaffUNet2.keras\")\n",
        "\n",
        "without_staff = remover.remove_staffs(chunks)"
      ],
      "metadata": {
        "id": "e14V1gfU1OiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final result\n",
        "\n",
        "Once we have the list of chunks with staff lines removed, we can use the function `reassemble_image` to rebuild the original image but without staffs."
      ],
      "metadata": {
        "id": "fSV7P6hrFutm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_image = reassemble_image(without_staff, new_w, new_h, 512)[:h, :w, :]\n",
        "show_image(symbols_image)"
      ],
      "metadata": {
        "id": "1-YqawAb1j2h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}